{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1\n",
    "In this tutorial we will build a neural network to classify images of fashion mnist dataset provided by tensorflow. We will for simplicity use only simple neural network uing Dense layers only. <br>\n",
    "lets first import our required libraries. Most used libraries are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using fashion mnist dataset provided by Tensorflow itself.<br>\n",
    "load_data method helps to get data !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x , train_y),(test_x,text_y) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check shapes of data received !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape # It means we have 60000 grayscale images of 28x28 size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape # It means that we have 60000 scalar output labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets reshape training and testing features into appropriate size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_copy = tf.reshape(train_x,(60000,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_copy = np.array(train_x_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_copy =np.array(tf.reshape(test_x,(10000,28,28,1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets view some images from training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_x_copy[9])\n",
    "print(train_y[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b31e1b9a58>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_x_copy[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_y[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step in building neural network is to specify <h1> Architecture </h1>\n",
    "Architecture means the overall design of model. We here specify, all the <h3> input hidden output layers </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#architecture \n",
    "''' first step is to build architecture of model'''\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28,1)))\n",
    "model.add(tf.keras.layers.Dense(units=16,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(units=64,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(units=128,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 23,258\n",
      "Trainable params: 23,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2\n",
    "''' second step is to compile model'''\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\" , optimizer=\"adam\" , metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.7523 - accuracy: 0.3064\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.3653 - accuracy: 0.4199\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.1553 - accuracy: 0.4969\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.9476 - accuracy: 0.5691\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.9069 - accuracy: 0.5962\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.8381 - accuracy: 0.6671\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.7376 - accuracy: 0.7250\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.6386 - accuracy: 0.7649\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5878 - accuracy: 0.7812\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5738 - accuracy: 0.7886\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5414 - accuracy: 0.8040\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5391 - accuracy: 0.8064\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5227 - accuracy: 0.8115\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5107 - accuracy: 0.8165\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5214 - accuracy: 0.8120\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5006 - accuracy: 0.8202\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5031 - accuracy: 0.8186\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5042 - accuracy: 0.8189\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5068 - accuracy: 0.8186\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4994 - accuracy: 0.8203\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4907 - accuracy: 0.8231\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5085 - accuracy: 0.8163\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4854 - accuracy: 0.8263\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4994 - accuracy: 0.8217\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4907 - accuracy: 0.8254\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4838 - accuracy: 0.8257\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4867 - accuracy: 0.8260\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4905 - accuracy: 0.8238\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4932 - accuracy: 0.8235\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4733 - accuracy: 0.8288\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4877 - accuracy: 0.8242\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4793 - accuracy: 0.8285\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4879 - accuracy: 0.8272\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4731 - accuracy: 0.8305\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4847 - accuracy: 0.8276\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4919 - accuracy: 0.8260\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4799 - accuracy: 0.8267\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4829 - accuracy: 0.8266\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4739 - accuracy: 0.8279\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4781 - accuracy: 0.8276\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4857 - accuracy: 0.8262\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4757 - accuracy: 0.8302\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4743 - accuracy: 0.8332\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4719 - accuracy: 0.8301\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4809 - accuracy: 0.8288\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4789 - accuracy: 0.8267\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4679 - accuracy: 0.8318\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4709 - accuracy: 0.8288\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4655 - accuracy: 0.8339\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4735 - accuracy: 0.8309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b31e465e48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 3\n",
    "''' third step is to fit/train model on training data'''\n",
    "model.fit(train_x_copy,train_y,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.5307 - accuracy: 0.8103\n"
     ]
    }
   ],
   "source": [
    "#step 4\n",
    "'''step 4 is to predict on test data. It is imp step so as to check if our model can do good on unseen data.'''\n",
    "evaluation=model.evaluate(test_x_copy,text_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss \\(testing\\): 0.5306618213653564\n",
      "Accuracy \\(testing\\) : 0.8102999925613403\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss \\(testing\\): {}\".format(evaluation[0]))\n",
    "print(\"Accuracy \\(testing\\) : {}\".format(evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have build a simple neural model with accuracy(testing) ~81%\n",
    "In next tutorial , we will build a model to classify fashion mnist data using <br>\n",
    "Convulational Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
